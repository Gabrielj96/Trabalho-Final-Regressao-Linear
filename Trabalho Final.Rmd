---
title: "R Notebook"
output: html_notebook
---

```{r include=FALSE}
library(dplyr)
library(corrplot)
library(car)
options(scipen = 999)
```

# **1. Capa**

![](lightweight_mmm.png)

## **Análise de Regressão Linear Múltipla: relações entre publicidade e receita**

Acadêmicos: Gabriel Augusto, Bruce Percílio e Fernando Ivan Meyer

# **2. Resumo**

Neste estudo, o objetivo foi entender os fatores que impactam a receita de uma empresa, considerando variáveis como gastos com publicidade em diferentes canais (TV, publicidade impressa, concorrência) e a ocorrência de eventos. Inicialmente, realizou-se uma análise de normalidade e correlação entre as variáveis, que revelou uma correlação positiva geral, sem problemas de multicolinearidade.

Para selecionar o modelo de regressão, utilizou-se o método forward, considerando tanto o critério AIC quanto o BIC. Ambos os critérios resultaram em modelos semelhantes, com exceção da variável de gastos com publicidade no Facebook (facebook_S), que foi excluída pelo critério BIC devido ao seu valor p superior a 0.10. O modelo final de regressão incluiu as variáveis de vendas do concorrente (competitor_sales_B), gastos com publicidade na TV (tv_S) e gastos com publicidade impressa (print_S).

Isso sugere que, para prever a receita da empresa, as estratégias de publicidade na TV e na mídia impressa, bem como o desempenho do concorrente, desempenham um papel significativo. Essa análise fornece insights valiosos para a tomada de decisões em marketing e estratégia de negócios, destacando as areas-chave nas quais a empresa deve focar para impulsionar sua receita.

# **3. Introdução**

A estatística está cada vez mais presente no mercado de publicidade, cada ano surgem novas ténicas, métodos e experimentos para impulsionar os resultados dos négocios.

Com o desuso cada vez mais frequente dos modelo de atribuição de marketing a análise de regressão vem substituindo os métodos tradicionais de entender a contribuição de cada canal de publicidade nos resultados finais

Sendo assim, o presente trabalho tem como objetivo entender a relação entre variáveis de publicidade, online e offline, na receita. Para isso foi utilizado a análise descritiva e a técnica de análise de regressão múltipla.

# **4. Materiais e Métodos**

A base de dados foi extraída do pacote Robyn, um pacote no R voltado para análises estatísticas para o mercado de publicidade criado pelo Facebook.

O arquivo conta com uma amostra de 208 observações semanais, uma variável data, uma variável dependente e 10 variáveis independentes.

## **Dicionário de Dados**

DATE = Data (por semana)

revenue = Receita

tv_S = Valor gasto com publicidade na TV

ooh_S = Valor gasto com publicidade Out of Home (Outdoors, pôsteres, painéis digitais, mídia aérea)

print_S = Valor gasto com publicidade impressa (Panfletos)

facebook_I = Impressões no Facebook

search_clicks_P = Cliques em anúncios nos mecanismos de busca (Google, Bing)

search_S = Valor gasto com publiciddade nos mecanismos de busca (Google, Bing)

competitor_sales_B = Vendas do concorrente

facebook_S = Valor gasto com publicidade no Facebook

events = Eventos ocorridos durante determinada semana

newsletter = Impressões no canal de notícias

O experimento iniciou-se observando cada variáveis e suas diferentes caracteríticas, depois fizemos uma análise de correlação para entender a relação entre variáveis independentes e dependente e problemas de multicolinearidade.

Feito a análise descritiva passamos para o primeiro ajuste do modelo apenas com intercepto, selecionamos o modelo com o metódo forward (AIC e BIC) e finalizamos com uma análise de resíduos.

**Gráfico 0. Dataframe**

```{r echo=FALSE}
df = read.csv("Marketing_regressao.csv")
head(df)
```

# **5. Resultados e Discussão**

### Sumário

Analisando o sumário já temos noção do tipo de dados que precisaremos trabalhar, segue abaixo um resumo:

Variáveis qualitativas: 2

Variáveis quantitativas: 10

Dessas 12 variáveis uma é a variável dependente.

**Gráfico 1. Resumo do dataframe**

```{r echo=FALSE}
as.data.frame(summary(df))
```

### Normalidade

A análise gráfico e shapiro wilk teste nos mostra um padrão não normal em todas as variáveis, algumas mais e outras menos.

O boxplot abaixo deixa mostra muitos outliers e a mediana sempre com determinado desvio, as variáveis mais próximas da normalidade são "revenue" e "competitor_sales_B".

**Gráfico 2. Boxplot das variáveis**

```{r echo=FALSE}
par(mfrow=c(1,3))
boxplot(df$revenue, ylab="Revenue")
boxplot(df$tv_S, ylab="tv_S")
boxplot(df$ooh_S, ylab="ooh_S")
boxplot(df$facebook_I, ylab="facebook_I")
boxplot(df$search_clicks_P, ylab="search_clicks_P")
boxplot(df$search_S, ylab="search_S")
boxplot(df$competitor_sales_B, ylab="competitor_sales_B")
boxplot(df$facebook_S, ylab="facebook_S")
boxplot(df$newsletter, ylab="newsletter")
```

Já o QQPLOT e QQLINE apresenta desvio dos pontos da linha de tendência, indicando possível anormalidade na distribuição dos dados.

**Gráfico 3. QQPLOT e QQLINE das variáveis**

```{r echo=FALSE}
par(mfrow=c(1,3))
qqnorm(df$revenue, ylab="Revenue"); qqline(df$revenue, ylab="Revenue")
qqnorm(df$tv_S, ylab="tv_S"); qqline(df$tv_S, ylab="tv_S")
qqnorm(df$ooh_S, ylab="ooh_S"); qqline(df$ooh_S, ylab="ooh_S")
qqnorm(df$facebook_I, ylab="facebook_I"); qqline(df$facebook_I, ylab="facebook_I")
qqnorm(df$search_clicks_P, ylab="search_clicks_P"); qqline(df$search_clicks_P, ylab="search_clicks_P")
qqnorm(df$search_S, ylab="search_S"); qqline(df$search_S, ylab="search_S")
qqnorm(df$competitor_sales_B, ylab="competitor_sales_B"); qqline(df$competitor_sales_B, ylab="competitor_sales_B")
qqnorm(df$facebook_S, ylab="facebook_S"); qqline(df$facebook_S, ylab="facebook_S")
qqnorm(df$newsletter, ylab="newsletter"); qqline(df$newsletter, ylab="newsletter")
```

E para confirmar a distribuição não-normal o shapiro-wilk teste rejeita a hipótese nula em todas as variáveis.

**Gráfico 4. Shapiro-wilk teste das variáveis**

```{r echo=FALSE}
df_shap = data.frame(Var = c("0"), P_value = c(0))
for (variable in colnames(subset(df, select = -c(DATE, events)))) {
  df_shap[nrow(df_shap) + 1,] = c(variable, shapiro.test(df[[variable]])[2])
}
df_shap
```

### Correlação

A análise de correlação mostra que todas variáveis tem certa correlação positiva com a variável dependente e não aparenta problemas de multicolinearidade, já que a correlação entre variáveis indepedentes não é muito alta.

**Gráfico 5. Correlação de pearson**

```{r echo=FALSE}
corrplot::corrplot(cor(df[, sapply(df, is.numeric)], method = "pearson"), method = 'number', type = 'lower', number.cex = 0.5, col=colorRampPalette(c("red","gray","blue"))(200))
```

### **Ajuste do Modelo**

Inicialmente ajustamos um modelo apenas com as variáveis de valor gasto com publicidade para cada canal apenas para ter uma noção do que podemos encontrar.

O modelo retornou significância para todas variáveis, porém pouco explica a variação da variável dependente com R² de 0.43.

**Gráfico 6. Resumo e Anova do primeiro modelo**

```{r echo=FALSE}
modelo = lm(revenue ~ tv_S + ooh_S + print_S + search_S + facebook_S, data = df)
summary(modelo)
anova(modelo)
```

### Seleção de Modelo (Método Forward)

Para a seleção do modelo utilizamos o método forward, tanto AIC como BIC.

```{r echo=FALSE}

modelo1 = lm(revenue ~ 1, data = df)
```

O modelo AIC e BIC foram bem parecidos com exceção da variável facebook_S que foi retirada pelo modelo BIC.

Considerando que a variável facebook_S tinha um valor p maior que 0.10 no modelo AIC faz sentido dizer que o modelo Forward BIC fez a melhor seleção de variáveis.

Modelo final = lm(formula = revenue \~ competitor_sales_B + tv_S + print_S, data = df)

**Gráfico 7. Resultados metódo forward (AIC e BIC)**

```{r echo=FALSE}
modelo_stepForward_AIC = step(modelo1, scope = ~tv_S + ooh_S + print_S + facebook_I + search_clicks_P + search_S + competitor_sales_B + facebook_S + newsletter, direction = 'forward', k = 2)

n = nrow(df)
modelo_stepForward_BIC = step(modelo1, scope = ~tv_S + ooh_S + print_S + facebook_I + search_clicks_P + search_S + competitor_sales_B + facebook_S + newsletter, direction = 'forward', k = log(n))
```

Os dois critérios resultaram em modelos bem parecidos e significantes com exceção da variáveis facebook_S que foi retirada pelo critério BIC já que o valor p era maior que 0.10.

**Gráfico 8. Resumo melhores modelos (AIC e BIC)**

```{r echo=FALSE}
summary(modelo_stepForward_AIC)
summary(modelo_stepForward_BIC)
```

Percebe-se os coeficientes dos modelos são bem próximos, apenas o intercepto do modelo 2 (BIC) é um pouco menor pela retirada da variável facebook_S

**Gráfico 9. Comparação de coeficientes (AIC e BIC)**

```{r echo=FALSE}
compareCoefs(modelo_stepForward_AIC, modelo_stepForward_BIC)
```

### **Avaliação dos Resíduos do Modelo**

Para análise dos resíduos, incialmente foi realizada uma análise gráfica, posteriormente foi realizado a avaliação da normalidade e da presença de outliers por testes estatísticos. Os resultados encontram-se abaixo:

**Modelo AIC**

**Gráfico 10. Resíduos do modelo (AIC)**

```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(modelo_stepForward_AIC, wich = c(1:4), pch = 20)
par(mfrow=c(1,1))
```

Observa-se, avaliando o gráfico *Residual vs Fitted* que é possivel identificar uma linearidade nos resíduos, no entanto os mesmos não seguem uma distribuição normal, uma vez que no gráfico *Q-Q Plot* foram observados vários pontos fora da linha de previsão.

No gráfico *Scale-Location* observa-se pontos fora do padrão, não podendo dizer atrávés dele se os resíduos são homocedásticos. Por fim, verifica-se que ha alguns pontos influentes, uma vez que no gráfico *Residual vs Leverage* ha pontos próximos aos limites.

Para confirmar a normalidade dos resíduos foi realizado o teste Shapiro-Wilk, obtendo a seguinte estatística:

**Gráfico 11. Teste de normalidade dos resíduos (AIC)**

```{r echo=FALSE}
shapiro.test(modelo_stepForward_AIC$residuals)
```

O teste de Shapiro-Wilk considera como hipótese nula a normalidade dos resíduos, como o valor encontrado ficou abaixo dos 5% a hipótese nula deve ser rejeitada assumindo a não normalidade dos resíduos da regressão.

A presença de outliers foi confimada através da função summary onde o output encontrado entre mínimo é máximo excede o intervalo -3 a +3.

**Gráfico 12. Resumo dos resíduos do modelo (AIC)**

```{r echo=FALSE}
summary(rstandard(modelo_stepForward_AIC))
```

**Modelo BIC**

A avaliação dos modelo BIC encontrou outputs semelhantes ao do modelo AIC.

**Gráfico 13. Resíduos do modelo (BIC)**

```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(modelo_stepForward_BIC, wich = c(1:4), pch = 20)
par(mfrow=c(1,1))
```

A analíse gráfica apresentou o mesmo padrão, sendo possível identificar pontos de outliers.

Ao realizar o teste de normalidade, observa-se que não é possível assumir a normalidade dos resíduos encontrados.

**Gráfico 14. Teste de normalidade dos resíduos (BIC)**

```{r echo=FALSE}
shapiro.test(modelo_stepForward_BIC$residuals)
```

A presença de outliers foi confimada através da função summary onde o output encontrado entre mínimo é máximo excede o intervalo -3 a +3.

**Gráfico 15. Resumo dos resíduos do modelo (BIC)**

```{r echo=FALSE}
summary(rstandard(modelo_stepForward_AIC))
```

A homocedasticidade e a interdependência dos resíduos foram avaliadas apenas graficamente uma vez que os outros pressupostos ja haviam sido feridos.

# **6. Conclusão**

O modelo final pode ser considerado um modelo bom já que todas as variáveis inputadas tem significancia estatística e o coeficiente de determinação foi de 0.86.

Tentamos ser o mais parcimoniosos possível aplicando análise descritiva, correlação, normalidade dos dados, além de utilizar o método forward pelos critérios AIC e BIC e análise dos resíduos.

Reconhecemos haver algumas limitações, poderíamos implementar algumas outras técnicas para haver mais confiança, como por exemplo, realizar estimação, predições e inferências, utilizar a técnica vif, diferentes métodos de seleção de modelo e diferentes métricas de análise do modelo.

Para futuros trabalhos pretendemos, além das limitações descritas acima, testar novos modelos com transformações nas variáveis devido a não-normalidades dos dados.
